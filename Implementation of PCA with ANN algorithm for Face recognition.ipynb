{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13715386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_gallery(images, title, h, w, n_row=3,n_col=4):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i+ 1)\n",
    "        plt.imshow(image[i].reshape((h, w)), cmap=plt.cm.gray)\n",
    "        plt.title(titles[i], size=12)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c10513bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'dataset/faces/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      5\u001b[0m Class_names\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m person_name \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(dir_name):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# print(person_name)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     dir_path \u001b[38;5;241m=\u001b[39m dir_name\u001b[38;5;241m+\u001b[39mperson_name\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m     Class_names\u001b[38;5;241m.\u001b[39mappend(person_name)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'dataset/faces/'"
     ]
    }
   ],
   "source": [
    "dir_name= \"dataset/faces/\"\n",
    "y=[];X=[];target_names=[]\n",
    "person_id=0;h=w=300\n",
    "n_samples=0\n",
    "Class_names=[]\n",
    "for person_name in os.listdir(dir_name):\n",
    "    # print(person_name)\n",
    "    dir_path = dir_name+person_name+\"/\"\n",
    "    Class_names.append(person_name)\n",
    "    for image_name in os.listdir(dir_path):\n",
    "        # formulate the image path\n",
    "        image_path = dir_path+image_name\n",
    "        # Read thee input image\n",
    "        img = cv2.imread(image_path)\n",
    "        # Convert  graysccale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        #resize image to 300*300 dimension\n",
    "        resized_image = cv2.resize(gray,(h,w))\n",
    "        # Covert matrix to vector\n",
    "        V = resized_image.flatten()\n",
    "        X.append(v)\n",
    "        # increase the number of samples\n",
    "        n_samples =n_samples+1\n",
    "        # Adding the categorical lable\n",
    "        y.append(person_id)\n",
    "        # adding the person name\n",
    "        target_names.append(person_name)\n",
    "# Increase the person id by 1\n",
    "person_id=person_id+1\n",
    "# ######################################################################################################################\n",
    "# transform list to numpy array\n",
    "y=np.array(y)\n",
    "X=np.array(X)\n",
    "target_names =np.array(target_names)\n",
    "n_features = X.shape[1]\n",
    "print(y.shape, X.shape, target_names.shape)\n",
    "print(\"Number of samples:\",n_samples)\n",
    "print(\"Total dataset size:\")\n",
    "print(\"n_samples: %d\" % n_samples)\n",
    "print(\"n_features: %d\" %n_features)\n",
    "print(\"n_classes: %d\" %n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e576d01e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.25 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# #########################################################################################\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# split into a training set and a test set using a stratified k fold\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# split into a training and testing set\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      6\u001b[0m n_components\u001b[38;5;241m+\u001b[39m \u001b[38;5;241m150\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting the top \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m eigenfaces from \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m faces\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39m (n_components, X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2617\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2614\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2616\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2617\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2618\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2619\u001b[0m )\n\u001b[0;32m   2621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2622\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2273\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2270\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2274\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2276\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2277\u001b[0m     )\n\u001b[0;32m   2279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.25 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "# #########################################################################################\n",
    "# split into a training set and a test set using a stratified k fold\n",
    "# split into a training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "n_components+ 150\n",
    "\n",
    "print(\"Extracting the top %d eigenfaces from %d faces\"% (n_components, X_train.shape[0]))\n",
    "\n",
    "#Applying PCA\n",
    "pca = PCA(n_components=n_components, svd_solver='randomized', whiten=True). fit(X_train)\n",
    "\n",
    "# generating eigenfaces\n",
    "eigenface = pca.components_.reshape((n_components, h, w))\n",
    "\n",
    "eigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\n",
    "plot_gallery(eigenfaces, eigenface_titles, h, w)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Projecting the input data on the eigenfaces orthonormal basis\")\n",
    "X_train_pca = pca.tansform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print(X_train_pca.shape, X_test_pca.shape)\n",
    "\n",
    "# %%Compute Fisherfaces\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "#Compute LDA of reduced data\n",
    "lda.fit(X_train_pca, y_train)\n",
    "\n",
    "X_train_lda = lda.transform(X_train_pca)\n",
    "X_test_lda = lda.transform(X_test_pca)\n",
    "print(\"Project done...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "765e12b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MLPClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Training with Multi Layer perception\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m clf \u001b[38;5;241m=\u001b[39m MLPClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, hidden_layer_sizes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m10\u001b[39m),max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mfit(X_train_lda, y_train)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Weights:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m model_info \u001b[38;5;241m=\u001b[39m [coef\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m coef \u001b[38;5;129;01min\u001b[39;00m clf\u001b[38;5;241m.\u001b[39mcoefs_]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MLPClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Training with Multi Layer perception\n",
    "clf = MLPClassifier(random_state=1, hidden_layer_sizes=(10,10),max_iter=1000, verbose=True).fit(X_train_lda, y_train)\n",
    "print(\"Model Weights:\")\n",
    "model_info = [coef.shape for coef in clf.coefs_]\n",
    "print(model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fee8981",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2606445904.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[18], line 16\u001b[1;36m\u001b[0m\n\u001b[1;33m    true positive = 0\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "y_pred=[];y_prob=[]\n",
    "for test_face in X_test_lda:\n",
    "    prob = clf.predict_proba([test_face])[0]\n",
    "    # print(prob, n.max(prob))\n",
    "    class_id = np.where(prob == np.max(prob))[0][0]\n",
    "    # print(class_index)\n",
    "    # find the label of the mathed facce\n",
    "    y_pred.append(class_id)\n",
    "    y_prob.append(np.max(prob))\n",
    "    \n",
    "# Transform the data\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "\n",
    "prediction_titles=[]\n",
    "true positive = 0\n",
    "for i in range(y_pred.shape[0]):\n",
    "    # print(y_test[i],y_pred[i])\n",
    "    # true_name = target_names[y_test[i]].rsplit(' ', 1)[-1]\n",
    "    # prdd_name = target_names[y_pred[i]].rsplit(' ', 1)[-1]\n",
    "    true_name = class_names[y_test[i]]\n",
    "    pred_name = class_names[y_pred[i]]\n",
    "    result = 'pred: %s, pr: %s \\ntrue: %s' %(pred_name, str(y_prob[i])[0:3], true_name)\n",
    "    # result = 'prediction: %s \\ntrue:      %s' %(pred_name, true_name)\n",
    "    prediction_titles.append(result)\n",
    "    if true_name==pred_name:\n",
    "        true_position =true_positive+1\n",
    "        \n",
    "print(\"Accuracy:\",true_position*100/y_pred.shape[0])\n",
    "\n",
    "\n",
    "# # plot results\n",
    "plot_gallery(X_test, prediction_titles, h, w)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ce9ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
